{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoiX2aCRCrVL"
   },
   "outputs": [],
   "source": [
    "!pip install -U openmim\n",
    "!mim install mmcv-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJOA2squDIu_"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/open-mmlab/mmdetection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTkFzSfoCrX7"
   },
   "outputs": [],
   "source": [
    "%cd mmdetection\n",
    "!pip install -v -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://public.roboflow.com/ds/xcrhGBJ1aB?key=bdAQK4gH2e\" > data_pets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip 'data_pets.zip' -d data_pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1j3cmyYDTEA"
   },
   "outputs": [],
   "source": [
    "!mkdir data_pets/annotations\n",
    "!mv data_pets/train/_annotations.coco.json data_pets/annotations/instances_train.json\n",
    "!mv data_pets/valid/_annotations.coco.json data_pets/annotations/instances_val.json\n",
    "!mv data_pets/test/_annotations.coco.json data_pets/annotations/instances_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGA0udZNlWYi"
   },
   "outputs": [],
   "source": [
    "%%writefile mmdet/models/backbones/my_model.py\n",
    "import torch.nn as nn\n",
    "from mmcv.runner import BaseModule\n",
    "from ..builder import BACKBONES\n",
    "\n",
    "@BACKBONES.register_module()\n",
    "class MyModel(BaseModule):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for i, out_channels in enumerate([128, 256, 512]):\n",
    "            block = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "                        kernel_size=3, stride=2, padding=1, bias=False),\n",
    "\n",
    "                  nn.BatchNorm2d(out_channels),\n",
    "                  nn.ReLU(inplace=True))\n",
    "\n",
    "            in_channels = out_channels\n",
    "            self.layers.append(block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for module in self.layers:\n",
    "            x = module(x)\n",
    "            outputs.append(x)\n",
    "        return tuple(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mmdet/models/backbones/my_model.py\n",
    "import torch.nn as nn\n",
    "from mmcv.cnn import build_conv_layer, build_norm_layer, build_activation_layer\n",
    "from mmcv.runner import BaseModule\n",
    "from ..builder import BACKBONES\n",
    "\n",
    "@BACKBONES.register_module()\n",
    "class MyModel(BaseModule):\n",
    "    def __init__(self, in_channels, stride=2, padding=1, conv_cfg=None, norm_cfg=dict(type='BN'), act_cfg=dict(type='ReLU')):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for i, out_channels in enumerate([128, 256, 512]):\n",
    "            block = nn.Sequential(build_conv_layer(conv_cfg, in_channels, out_channels, kernel_size=3, \n",
    "                                          stride=stride, padding=padding, bias=False),\n",
    "            \n",
    "                                  build_norm_layer(norm_cfg, out_channels)[1],\n",
    "                                  build_activation_layer(act_cfg))\n",
    "\n",
    "            in_channels = out_channels\n",
    "            self.layers.append(block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for module in self.layers:\n",
    "            x = module(x)\n",
    "            outputs.append(x)\n",
    "        return tuple(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DhN7BCxmnboD"
   },
   "outputs": [],
   "source": [
    "%%writefile mmdet/models/backbones/__init__.py\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from .csp_darknet import CSPDarknet\n",
    "from .darknet import Darknet\n",
    "from .detectors_resnet import DetectoRS_ResNet\n",
    "from .detectors_resnext import DetectoRS_ResNeXt\n",
    "from .efficientnet import EfficientNet\n",
    "from .hourglass import HourglassNet\n",
    "from .hrnet import HRNet\n",
    "from .mobilenet_v2 import MobileNetV2\n",
    "from .pvt import PyramidVisionTransformer, PyramidVisionTransformerV2\n",
    "from .regnet import RegNet\n",
    "from .res2net import Res2Net\n",
    "from .resnest import ResNeSt\n",
    "from .resnet import ResNet, ResNetV1d\n",
    "from .resnext import ResNeXt\n",
    "from .ssd_vgg import SSDVGG\n",
    "from .swin import SwinTransformer\n",
    "from .trident_resnet import TridentResNet\n",
    "from .my_model import MyModel\n",
    "\n",
    "__all__ = [\n",
    "    'RegNet', 'ResNet', 'ResNetV1d', 'ResNeXt', 'SSDVGG', 'HRNet',\n",
    "    'MobileNetV2', 'Res2Net', 'HourglassNet', 'DetectoRS_ResNet',\n",
    "    'DetectoRS_ResNeXt', 'Darknet', 'ResNeSt', 'TridentResNet', 'CSPDarknet',\n",
    "    'SwinTransformer', 'PyramidVisionTransformer',\n",
    "    'PyramidVisionTransformerV2', 'EfficientNet', 'MyModel'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVZiebJa63sw"
   },
   "outputs": [],
   "source": [
    "!mkdir configs/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCHiYMIVopaD"
   },
   "outputs": [],
   "source": [
    "%%writefile configs/my_model/my_model_fpn_1x_coco.py\n",
    "_base_ = [\n",
    "    '../_base_/schedules/schedule_1x.py', \n",
    "    '../_base_/default_runtime.py'\n",
    "]\n",
    "\n",
    "# model settings\n",
    "model = dict(\n",
    "    type='FasterRCNN',\n",
    "    backbone=dict(\n",
    "        type='MyModel',\n",
    "        in_channels=3),\n",
    "    neck=dict(\n",
    "        type='FPN',\n",
    "        in_channels=[128, 256, 512],\n",
    "        out_channels=256,\n",
    "        num_outs=5),\n",
    "    rpn_head=dict(\n",
    "        type='RPNHead',\n",
    "        in_channels=256,\n",
    "        feat_channels=256,\n",
    "        anchor_generator=dict(\n",
    "            type='AnchorGenerator',\n",
    "            scales=[8],\n",
    "            ratios=[0.5, 1.0, 2.0],\n",
    "            strides=[4, 8, 16, 32, 64]),\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHBBoxCoder',\n",
    "            target_means=[.0, .0, .0, .0],\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
    "    roi_head=dict(\n",
    "        type='StandardRoIHead',\n",
    "        bbox_roi_extractor=dict(\n",
    "            type='SingleRoIExtractor',\n",
    "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
    "            out_channels=256,\n",
    "            featmap_strides=[4, 8, 16, 32]),\n",
    "        bbox_head=dict(\n",
    "            type='Shared2FCBBoxHead',\n",
    "            in_channels=256,\n",
    "            fc_out_channels=1024,\n",
    "            roi_feat_size=7,\n",
    "            num_classes=80,\n",
    "            bbox_coder=dict(\n",
    "                type='DeltaXYWHBBoxCoder',\n",
    "                target_means=[0., 0., 0., 0.],\n",
    "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
    "            reg_class_agnostic=False,\n",
    "            loss_cls=dict(\n",
    "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
    "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
    "\n",
    "    # model training and testing settings\n",
    "    train_cfg=dict(\n",
    "        rpn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.7,\n",
    "                neg_iou_thr=0.3,\n",
    "                min_pos_iou=0.3,\n",
    "                match_low_quality=True,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=256,\n",
    "                pos_fraction=0.5,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=False),\n",
    "            allowed_border=-1,\n",
    "            pos_weight=-1,\n",
    "            debug=False),\n",
    "        rpn_proposal=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=1000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.5,\n",
    "                neg_iou_thr=0.5,\n",
    "                min_pos_iou=0.5,\n",
    "                match_low_quality=False,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=512,\n",
    "                pos_fraction=0.25,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=True),\n",
    "            pos_weight=-1,\n",
    "            debug=False)),\n",
    "    test_cfg=dict(\n",
    "        rpn=dict(\n",
    "            nms_pre=1000,\n",
    "            max_per_img=1000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            score_thr=0.05,\n",
    "            nms=dict(type='nms', iou_threshold=0.5),\n",
    "            max_per_img=100)\n",
    "        # soft-nms is also supported for rcnn testing\n",
    "        # e.g., nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)\n",
    "    ))\n",
    "\n",
    "# dataset settings\n",
    "dataset_type = 'CocoDataset'\n",
    "data_root = 'data_pets/'\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1333, 800),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'annotations/instances_train.json',\n",
    "        img_prefix=data_root + 'train/',\n",
    "        pipeline=train_pipeline),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'annotations/instances_val.json',\n",
    "        img_prefix=data_root + 'valid/',\n",
    "        pipeline=test_pipeline),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'annotations/instances_test.json',\n",
    "        img_prefix=data_root + 'test/',\n",
    "        pipeline=test_pipeline))\n",
    "evaluation = dict(interval=1, metric='bbox')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "508YcJpAnbqY"
   },
   "outputs": [],
   "source": [
    "! python tools/train.py configs/my_model/my_model_fpn_1x_coco.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65IcSYPllPw6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMmlC6I7/xnqudQ7IqJTJmc",
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
